@misc{VisionMiddleburyEdu,
  title = {Vision.Middlebury.Edu/Stereo/Data},
  urldate = {2023-11-23},
  howpublished = {https://vision.middlebury.edu/stereo/data/},
  file = {/Users/newt/Zotero/storage/W3B6P5NJ/data.html}
}
@article{beyerAmesStereoPipeline2018,
  title = {The {{Ames Stereo Pipeline}}: {{NASA}}'s {{Open Source Software}} for {{Deriving}} and {{Processing Terrain Data}}},
  shorttitle = {The {{Ames Stereo Pipeline}}},
  author = {Beyer, Ross A. and Alexandrov, Oleg and McMichael, Scott},
  year = {2018},
  journal = {Earth and Space Science},
  volume = {5},
  number = {9},
  pages = {537--548},
  issn = {2333-5084},
  doi = {10.1029/2018EA000409},
  urldate = {2023-11-23},
  abstract = {The NASA Ames Stereo Pipeline is a suite of free and open source automated geodesy and stereogrammetry tools designed for processing stereo images captured from satellites (around Earth and other planets), robotic rovers, aerial cameras, and historical images, with and without accurate camera pose information. It produces cartographic products, including digital terrain models, ortho-projected images, 3-D models, and bundle-adjusted networks of cameras. Ames Stereo Pipeline's data products are suitable for science analysis, mission planning, and public outreach.},
  copyright = {\textcopyright 2018. The Authors.},
  langid = {english},
  file = {/Users/newt/Zotero/storage/E9KCCYUH/Beyer et al. - 2018 - The Ames Stereo Pipeline NASA's Open Source Softw.pdf;/Users/newt/Zotero/storage/6GKQFTZX/2018EA000409.html}
}
@incollection{lindebergScaleInvariantFeature2012,
  title = {Scale {{Invariant Feature Transform}}},
  booktitle = {Scholarpedia},
  author = {Lindeberg, Tony},
  year = {2012},
  month = may,
  volume = {7},
  doi = {10.4249/scholarpedia.10491},
  abstract = {Scale Invariant Feature Transform (SIFT) is an image descriptor for image-based matching developed by David Lowe (1999, 2004). This descriptor as well as related image descriptors are used for a large number of purposes in computer vision related to point matching between different views of a 3-D scene and view-based object recognition. The SIFT descriptor is invariant to translations, rotations and scaling transformations in the image domain and robust to moderate perspective transformations and illumination variations. Experimentally, the SIFT descriptor has been proven to be very useful in practice for image matching and object recognition under real-world conditions. In its original formulation, the SIFT descriptor comprised a method for detecting interest points from a grey-level image at which statistics of local gradient directions of image intensities were accumulated to give a summarizing description of the local image structures in a local neighbourhood around each interest point, with the intention that this descriptor should be used for matching corresponding interest points between different images. Later, the SIFT descriptor has also been applied at dense grids (dense SIFT) which have been shown to lead to better performance for tasks such as object categorization, texture classification, image alignment and biometrics . The SIFT descriptor has also been extended from grey-level to colour images and from 2-D spatial images to 2+1-D spatio-temporal video.},
  file = {/Users/newt/Zotero/storage/3R6RYEW6/Lindeberg - 2012 - Scale Invariant Feature Transform.pdf}
}

@article{fischlerRandomSampleConsensus1981,
  title = {Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography},
  shorttitle = {Random Sample Consensus},
  author = {Fischler, Martin A. and Bolles, Robert C.},
  year = {1981},
  month = jun,
  journal = {Communications of the ACM},
  volume = {24},
  number = {6},
  pages = {381--395},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/358669.358692},
  urldate = {2023-11-23},
  abstract = {A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced. RANSAC is capable of interpreting/smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing},
  langid = {english}
}


@article{kolomogorov,
  author={Kolmogorov, V. and Zabih, R.},
  booktitle={Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001}, 
  title={Computing visual correspondence with occlusions using graph cuts}, 
  year={2001},
  volume={2},
  number={},
  pages={508-515 vol.2},
  doi={10.1109/ICCV.2001.937668}}
